# ğŸ¤– AI Digital Twin

An AI-powered Digital Twin chatbot that represents you on your personal/professional website. Built with FastAPI, OpenAI GPT-4o-mini, and deployable to AWS using Terraform.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Local Development](#local-development)
- [AWS Deployment](#aws-deployment)
- [Configuration](#configuration)
- [API Reference](#api-reference)

## Overview

This project creates a conversational AI agent that acts as your "digital twin" - an AI representation of yourself that can engage with website visitors, answer questions about your professional background, skills, and experience.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸŒ Website Visitor                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ğŸ’¬ "Tell me about yourself"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ğŸ¤– AI Digital Twin                         â”‚
â”‚                                                                  â”‚
â”‚   "Hi! I'm Kedarnadh. With 19+ years in cloud modernization     â”‚
â”‚    and software development, I've focused on data-driven         â”‚
â”‚    solutions and fostering collaboration..."                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Architecture

### High-Level Architecture

```mermaid
flowchart TB
    subgraph Client["ğŸ–¥ï¸ Frontend"]
        UI[Next.js Static Site]
    end

    subgraph AWS["â˜ï¸ AWS Cloud"]
        S3F[("ğŸ“¦ S3 Frontend\n(Static Website)")]
        APIGW[ğŸ”€ API Gateway]
        Lambda[âš¡ Lambda Function]
        S3M[("ğŸ’¾ S3 Memory\n(Conversations)")]
    end

    subgraph External["ğŸŒ External Services"]
        OpenAI[ğŸ§  OpenAI API\nGPT-4o-mini]
    end

    UI --> S3F
    S3F --> APIGW
    APIGW --> Lambda
    Lambda --> S3M
    Lambda --> OpenAI
```

### Request Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API Gateway
    participant Lambda
    participant S3
    participant OpenAI

    User->>Frontend: Send message
    Frontend->>API Gateway: POST /chat
    API Gateway->>Lambda: Invoke function
    Lambda->>S3: Load conversation history
    S3-->>Lambda: Previous messages
    Lambda->>OpenAI: Chat completion request
    OpenAI-->>Lambda: AI response
    Lambda->>S3: Save updated conversation
    Lambda-->>API Gateway: Response
    API Gateway-->>Frontend: JSON response
    Frontend-->>User: Display message
```

### Local Development Architecture

```mermaid
flowchart LR
    subgraph Local["ğŸ’» Local Development"]
        FE[Frontend\nNext.js :3000]
        BE[Backend\nFastAPI :8000]
        MEM[("ğŸ“ Local Memory\n./memory/")]
    end

    subgraph External["ğŸŒ External"]
        OAI[OpenAI API]
    end

    FE <-->|HTTP| BE
    BE <-->|Read/Write| MEM
    BE <-->|API Calls| OAI
```

## Features

- ğŸ­ **Personalized AI Responses** - Trained on your profile, LinkedIn, and communication style
- ğŸ’¬ **Conversation Memory** - Maintains context across messages within a session
- ğŸ”„ **Session Management** - Unique session IDs for each conversation
- â˜ï¸ **Serverless Deployment** - Runs on AWS Lambda for cost-effective scaling
- ğŸ—ï¸ **Infrastructure as Code** - Full Terraform configuration for AWS resources
- ğŸ”’ **CORS Protected** - Secure cross-origin request handling

## Project Structure

```
twin/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.py           # FastAPI application
â”‚   â”œâ”€â”€ context.py          # AI prompt engineering
â”‚   â”œâ”€â”€ resources.py        # Data loading utilities
â”‚   â”œâ”€â”€ lambda_handler.py   # AWS Lambda entry point
â”‚   â”œâ”€â”€ deploy.py           # Lambda packaging script
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ summary.txt     # Your professional summary
â”‚       â”œâ”€â”€ style.txt       # Communication style notes
â”‚       â”œâ”€â”€ facts.json      # Basic facts (name, etc.)
â”‚       â””â”€â”€ Profile.pdf     # LinkedIn profile export
â”‚
â”œâ”€â”€ memory/                  # Local conversation storage
â”‚   â””â”€â”€ {session_id}.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh           # Deployment automation
â”‚   â””â”€â”€ destroy.sh          # Infrastructure teardown
â”‚
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf             # AWS resources definition
â”‚   â”œâ”€â”€ variables.tf        # Input variables
â”‚   â”œâ”€â”€ outputs.tf          # Output values
â”‚   â”œâ”€â”€ versions.tf         # Provider configuration
â”‚   â””â”€â”€ terraform.tfvars    # Variable values
â”‚
â””â”€â”€ README.md
```

## Getting Started

### Prerequisites

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) (Python package manager)
- Node.js 18+ (for frontend)
- AWS CLI configured
- Terraform 1.0+
- Podman or Docker (for Lambda packaging)
- OpenAI API key

### Environment Variables

Create a `.env` file in the `backend/` directory:

```env
OPENAI_API_KEY=sk-your-openai-api-key
CORS_ORIGINS=http://localhost:3000
USE_S3=false
MEMORY_DIR=../memory
```

## Local Development

### Backend

```bash
cd backend

# Initialize Python environment
uv init --bare
uv python pin 3.12
uv add -r requirements.txt

# Run the server
uv run uvicorn server:app --reload
```

The API will be available at `http://localhost:8000`

### Frontend

```bash
cd frontend

npm install
npm run dev
```

The frontend will be available at `http://localhost:3000`

## AWS Deployment

### Quick Deploy

```bash
# Set your OpenAI API key
export TF_VAR_openai_api_key="sk-your-key-here"

# Deploy to AWS (default: dev environment)
./scripts/deploy.sh

# Deploy to test environment
./scripts/deploy.sh test

# Deploy to production
./scripts/deploy.sh prod
```

### What Gets Created

| Resource | Purpose |
|----------|---------|
| **S3 Frontend Bucket** | Hosts static website files |
| **S3 Memory Bucket** | Stores conversation history |
| **Lambda Function** | Runs the FastAPI backend |
| **API Gateway** | HTTP endpoints for the API |
| **IAM Role** | Permissions for Lambda |

### Teardown

```bash
# Destroy dev environment
./scripts/destroy.sh dev

# Destroy test environment
./scripts/destroy.sh test
```

## Configuration

### Customizing Your Digital Twin

1. **Edit `backend/data/summary.txt`** - Your professional summary
2. **Edit `backend/data/style.txt`** - Your communication style preferences
3. **Edit `backend/data/facts.json`** - Basic facts about you:
   ```json
   {
     "full_name": "Your Full Name",
     "name": "Your Preferred Name"
   }
   ```
4. **Add `backend/data/linkedin.pdf`** - Export of your LinkedIn profile

### Terraform Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `project_name` | Resource name prefix | `twin` |
| `environment` | Environment (dev/test/prod) | `dev` |
| `lambda_timeout` | Lambda timeout in seconds | `60` |
| `api_throttle_burst_limit` | API burst limit | `10` |
| `api_throttle_rate_limit` | API rate limit | `5` |
| `openai_api_key` | OpenAI API key | (required) |

## API Reference

### Endpoints

#### `GET /`
Returns API information.

```json
{
  "message": "AI Digital Twin API",
  "memory_enabled": true,
  "storage": "local"
}
```

#### `GET /health`
Health check endpoint.

```json
{
  "status": "healthy",
  "use_s3": false
}
```

#### `POST /chat`
Send a message to the Digital Twin.

**Request:**
```json
{
  "message": "Tell me about your experience",
  "session_id": "optional-session-id"
}
```

**Response:**
```json
{
  "response": "With over 19 years of experience...",
  "session_id": "generated-or-provided-id"
}
```

#### `GET /conversation/{session_id}`
Retrieve conversation history.

**Response:**
```json
{
  "session_id": "abc-123",
  "messages": [
    {
      "role": "user",
      "content": "Hello",
      "timestamp": "2025-01-15T10:30:00"
    },
    {
      "role": "assistant", 
      "content": "Hi! I'm Kedarnadh...",
      "timestamp": "2025-01-15T10:30:01"
    }
  ]
}
```

## ğŸ“ License

This project is for educational purposes as part of an AI deployment course.

## ğŸ™ Acknowledgments

- Built as part of the Agentic AI Production Deployment course
- Powered by OpenAI GPT-4o-mini
- Infrastructure managed with Terraform

